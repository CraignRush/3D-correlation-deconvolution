{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys, logging\n",
    "importlib.reload(logging)\n",
    "LOG_LEVEL = logging.INFO\n",
    "logging.basicConfig(filename='current.log',encoding='utf-8',level=LOG_LEVEL, filemode = 'w', format='%(asctime)s-%(levelname)s: Process %(process)d said: %(message)s')\n",
    "log = logging.getLogger()\n",
    "log.addHandler(logging.StreamHandler(sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 18:11:09.733825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-05-03 18:11:18.027787: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-05-03 18:11:18.071307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:03:00.0 name: NVIDIA L40S computeCapability: 8.9\n",
      "coreClock: 2.52GHz coreCount: 142 deviceMemorySize: 44.53GiB deviceMemoryBandwidth: 804.75GiB/s\n",
      "2024-05-03 18:11:18.071399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-05-03 18:11:18.212809: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-05-03 18:11:18.212994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-05-03 18:11:18.276836: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-05-03 18:11:18.337908: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-05-03 18:11:18.433097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-05-03 18:11:18.493334: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-05-03 18:11:18.701696: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-05-03 18:11:18.719492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "#os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '256'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "## Check if Tensorflow really runs on your GPU\n",
    "# refer first to the README (!), then to this article, especially if you are using a windows machine https://www.tensorflow.org/install/pip#windows-wsl2_1\n",
    "#tf_config = tf.config.list_physical_devices('GPU')\n",
    "#logging.debug(\"Num GPUs Available: {}\".format(len(tf.config.list_physical_devices('GPU'))))\n",
    "#logging.debug(tf_config)\n",
    "    \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "#   try:\n",
    "#     #tf.config.experimental.set_virtual_device_configuration(gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "#     logging.debug(tf.config.experimental.set_memory_growth(gpus[0], True))\n",
    "#     logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#     logging.debug((len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\"))\n",
    "#   except RuntimeError as e:\n",
    "#     # Virtual devices must be set before GPUs have been initialized\n",
    "#     logging.debug(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'FOV' from 'FOV' (/fs/gpfs41/lv01/fileset02/pool/pool-plitzko3/Johann/04-Programs/3D-correlation-deconvonvolution/FOV.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mFOV\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FOV\n\u001b[1;32m     15\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'FOV' from 'FOV' (/fs/gpfs41/lv01/fileset02/pool/pool-plitzko3/Johann/04-Programs/3D-correlation-deconvonvolution/FOV.py)"
     ]
    }
   ],
   "source": [
    "#TODO fix import and order\n",
    "from skimage import exposure, io\n",
    "from flowdec import data as tfd_data\n",
    "from flowdec import psf as tfd_psf\n",
    "from flowdec import restoration as tfd_restoration\n",
    "from skimage.transform import rescale\n",
    "from skimage.metrics import mean_squared_error, peak_signal_noise_ratio, structural_similarity\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "from FOV import LIF_info\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npsf = np.zeros_like(stack_scaled)\\npsf = tfd_psf.GibsonLanni(\\n    na=NA,           # Numerical aperture\\n    m=M,             # Magnification\\n    ni0=ni0,         # Immersion RI\\n    res_lateral=res_lateral, # X/Y resolution\\n    res_axial=res_axial,     # Axial resolution\\n    wavelength=wavelength,  # Emission wavelength \\n    size_x=np.max((size_x, int(stack_scaled.shape[2]))), \\n    size_y=np.max((size_y, int(stack_scaled.shape[1]))), \\n    size_z=np.min((size_z, int(stack_scaled.shape[0]))),\\n    ns = ns,\\n    ng0 = ng0,\\n    ti0 = ti0,\\n    tg0 = tg0,\\n).generate()\\nlogging.debug((psf.shape, psf.dtype))\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is meant to be representative of the arctis 100x widefield image capture (all distance units are in microns)\n",
    "# FIXME Export psfs into repo\n",
    "\n",
    "'''\n",
    "psf = np.zeros_like(stack_scaled)\n",
    "psf = tfd_psf.GibsonLanni(\n",
    "    na=NA,           # Numerical aperture\n",
    "    m=M,             # Magnification\n",
    "    ni0=ni0,         # Immersion RI\n",
    "    res_lateral=res_lateral, # X/Y resolution\n",
    "    res_axial=res_axial,     # Axial resolution\n",
    "    wavelength=wavelength,  # Emission wavelength \n",
    "    size_x=np.max((size_x, int(stack_scaled.shape[2]))), \n",
    "    size_y=np.max((size_y, int(stack_scaled.shape[1]))), \n",
    "    size_z=np.min((size_z, int(stack_scaled.shape[0]))),\n",
    "    ns = ns,\n",
    "    ng0 = ng0,\n",
    "    ti0 = ti0,\n",
    "    tg0 = tg0,\n",
    ").generate()\n",
    "logging.debug((psf.shape, psf.dtype))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Microscope Parameters from the Arctis 100x iFLM\n",
    "# Image properties\n",
    "# Size of the PSF array, pixels\n",
    "size_x = 256\n",
    "size_y = 256\n",
    "size_z = 128\n",
    "#\n",
    "# # Microscope parameters\n",
    "NA          = 0.9\n",
    "wavelength  = 0.588 # microns\n",
    "M           = 100   # magnification\n",
    "ns          = 1.0  # specimen refractive index (RI)\n",
    "ng0         = 1.0   # coverslip RI design value\n",
    "ni0         = 1.0   # immersion medium RI design value\n",
    "ti0         = 7500   # microns, working distance (immersion medium thickness) design value\n",
    "tg0         = 0   # microns, coverslip thickness design value\n",
    "res_lateral = 0.075   # microns\n",
    "res_axial   = 0.25  # microns\n",
    "\n",
    "# ng          = 1.5   # coverslip RI experimental value (defaults to ng0 if not given)\n",
    "# ni          = 1.5   # immersion medium RI experimental value (defaults to ni0 if not given)\n",
    "# tg          = 170   # microns, coverslip thickness experimental value (defaults to tg0 if not given)\n",
    "# pZ          = 2     # microns, particle distance from coverslip\n",
    "#\n",
    "# # Precision control\n",
    "# num_basis    = 100  # Number of rescaled Bessels that approximate the phase function\n",
    "# num_samples  = 1000 # Number of pupil samples along radial direction\n",
    "# oversampling = 2    # Defines the upsampling ratio on the image space grid for computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current File: /fs/pool/pool-plitzko3/Johann/03-Data/04-LightMicroscopy/EMBO_course_decon_testing/RAGE_01.lif\n"
     ]
    }
   ],
   "source": [
    "# Set directory of image stack\n",
    "# TODO explain: sudo mount -t drvfs '//samba-pool-pool-plitzko3.biochem.mpg.de/pool-plitzko3' /mnt/plitzko3\n",
    "file_pattern = '/fs/pool/pool-plitzko3/Johann/03-Data/04-LightMicroscopy/EMBO_course_decon_testing/RAGE_01.lif'#\n",
    "\n",
    "#'/fs/pool/pool-pub/EMBO/FLM/PreImaged_Yeast/20240402_Yeast_CA_GE_05/CA_GE_05_tiles.lif'\n",
    "output_folder = '/fs/pool/pool-plitzko3/Johann/03-Data/04-LightMicroscopy/EMBO_course_decon_testing/'\n",
    "#'/fs/pool/pool-pub/EMBO/FLM/PreImaged_Yeast/20240402_Yeast_CA_GE_05/'#\n",
    "LIFFILE = True\n",
    "logging.info(\"Current File: {}\".format(file_pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from FOV import LIF_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos_01\n"
     ]
    }
   ],
   "source": [
    "# Import LIF data with a custom written handler class here\n",
    "# FIXME Comment class properly\n",
    "# HACK Loop over all FOVs\n",
    "#HACK handle exceptions in class\n",
    "#TODO calibrate images\n",
    "#TODO in the very future optimize import, this takes ages!!!\n",
    "#TODO map to overview\n",
    "\n",
    "\n",
    "if LIFFILE:\n",
    "    test_fov = LIF_info(file_pattern,0)\n",
    "    logging.info(test_fov.FOV_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fov.selected_FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.748486328125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fov.resolution[test_fov.resolution['dimension_name'] == 'x']['resolution_nm'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIFFILE:\n",
    "    test_stack = test_fov.get_channel_stack(channel_num=range(test_fov.num_channels))\n",
    "    logging.debug(test_stack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if LIFFILE:\n",
    "    if len(test_stack.shape) == 4:\n",
    "        num = test_stack.shape[0]\n",
    "    else:\n",
    "        num = 1\n",
    "    fig,ax = plt.subplots(1,num, figsize=(15,5))\n",
    "    for chan in range(num):\n",
    "        if num == 1:\n",
    "            ax.imshow(np.max(test_stack,axis=0))\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax[chan].imshow(np.max(test_stack[chan],axis=0))\n",
    "            ax[chan].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image stack for debugging\n",
    "if not LIFFILE:\n",
    "    stack = io.imread('input.tif', plugin=\"tifffile\")\n",
    "else:    \n",
    "    if len(test_stack.shape) == 4:\n",
    "        stack = test_stack[0]\n",
    "    else:\n",
    "        stack = test_stack\n",
    "logging.info('Input stack shape: {}, dtype: {}'.format(stack.shape,stack.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalexy, scalez = 1, 1\n",
    "if np.max(scalexy) == 1 and np.max(scalez) == 1:\n",
    "    stack_scaled = stack\n",
    "else:\n",
    "    stack_scaled = rescale(stack, (scalez,scalexy,scalexy), mode='constant', order=2, anti_aliasing=True) \n",
    "logging.debug(stack_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is meant to be representative of the arctis 100x widefield image capture (all distance units are in microns)\n",
    "'''\n",
    "psf = np.zeros_like(stack_scaled)\n",
    "psf = tfd_psf.GibsonLanni(\n",
    "    na=NA,           # Numerical aperture\n",
    "    m=M,             # Magnification\n",
    "    ni0=ni0,         # Immersion RI\n",
    "    res_lateral=res_lateral, # X/Y resolution\n",
    "    res_axial=res_axial,     # Axial resolution\n",
    "    wavelength=wavelength,  # Emission wavelength \n",
    "    size_x=np.max((size_x, int(stack_scaled.shape[2]))), \n",
    "    size_y=np.max((size_y, int(stack_scaled.shape[1]))), \n",
    "    size_z=np.min((size_z, int(stack_scaled.shape[0]))),\n",
    "    ns = ns,\n",
    "    ng0 = ng0,\n",
    "    ti0 = ti0,\n",
    "    tg0 = tg0,\n",
    ").generate()\n",
    "logging.debug((psf.shape, psf.dtype))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIFFILE:\n",
    "    psf_var = tfd_psf.GibsonLanni(\n",
    "        na          = test_fov.NA,                           # Numerical aperture\n",
    "        m           = test_fov.mag,                          # Magnification\n",
    "        ni0         = 1.0,                                   # Immersion RI\n",
    "        res_lateral = float(test_fov.resolution[test_fov.resolution['dimension_name'] == 'x']['resolution_nm'].values[0] / 1000) , # X/Y resolution\n",
    "        res_axial   = float(test_fov.resolution[test_fov.resolution['dimension_name'] == 'z']['resolution_nm'].values[0] / 1000), # Axial resolution\n",
    "        wavelength  = float(test_fov.channels[0]['center_wavelength'] / 1000),  # Emission wavelength \n",
    "        size_x      = int(np.max((size_x, int(stack_scaled.shape[2])))), \n",
    "        size_y      = int(np.max((size_y, int(stack_scaled.shape[1])))), \n",
    "        size_z      = int(np.min((size_z, int(stack_scaled.shape[0])))),\n",
    "        ns          = 1.0,                                     # specimen refractive index (RI)\n",
    "        ng0         = 1.0,                                     # Refractive index of coverslip\n",
    "        ti0         = float(test_fov.working_distance_mm * 1000),     # microns, working distance (immersion medium thickness) design value\n",
    "        tg0         = 0,                                     # microns, coverslip thickness design value\n",
    "    )\n",
    "    psf_var.save('./current_psf.json')\n",
    "    psf = psf_var.generate().astype(np.uint8)\n",
    "    logging.info('PSF shape: {}, PSF dtype: {}'.format(psf.shape, psf.dtype))\n",
    "    logging.info('PSF: ' + psf_var.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is meant to be representative of the Leica SP8 50x widefield image capture (all distance units are in microns)\n",
    "# %%\n",
    "# This is meant to be representative of the Leica SP8 50x widefield image capture (all distance units are in microns)\n",
    "if not LIFFILE:\n",
    "    psf = np.zeros_like(stack_scaled)\n",
    "    psf = tfd_psf.GibsonLanni(\n",
    "        na=0.9,           # Numerical aperture\n",
    "        m=52.5,             # Magnification\n",
    "        ni0=ni0,         # Immersion RI\n",
    "        res_lateral=0.085, # X/Y resolution\n",
    "        res_axial=0.3,     # Axial resolution\n",
    "        wavelength=0.58,  # Emission wavelength \n",
    "        size_x=np.max((size_x, int(stack_scaled.shape[2]))), \n",
    "        size_y=np.max((size_y, int(stack_scaled.shape[1]))), \n",
    "        size_z=np.min((size_z, int(stack_scaled.shape[0]))),\n",
    "        ns          = 1,                                     # specimen refractive index (RI)\n",
    "        ng0         = 1,                                     # Refractive index of coverslip\n",
    "        ti0         =  280,     # microns, working distance (immersion medium thickness) design value\n",
    "        tg0 = tg0,\n",
    "    ).generate()\n",
    "    logging.info((psf.shape, psf.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case your GPU setup allows for a continuous oberserver or saving of intermediate steps (requires more memory, and is not used here)\n",
    "imgs = []\n",
    "scores = {}\n",
    "def observer(img, i, *args):\n",
    "    imgs.append(img)\n",
    "    scores[i] = {\n",
    "    'mse': mean_squared_error(stack_scaled, img),\n",
    "    #'ssim': structural_similarity(stack_scaled, img, data_range=1), #TODO find out why SSIM doesn't work as expected\n",
    "    'psnr': peak_signal_noise_ratio(stack_scaled, img)\n",
    "    }\n",
    "    \n",
    "    if i % 1 == 0:\n",
    "        if i == 1:\n",
    "            logging.info('Observing iteration = {} (dtype = {}, max = {:.3f})'.format(i, img.dtype, img.max()))        \n",
    "        else:            \n",
    "            #logging.info('Observing iteration = {} (MSE = {:.2f},SSIM = {:.2f}, PSNR = {:.2f})'.format(i, scores[i]['mse'],scores[i]['ssim'],scores[i]['psnr']))        \n",
    "            logging.info('Observing iteration = {} (MSE = {:.2f}, PSNR = {:.2f})'.format(i, scores[i]['mse'],scores[i]['psnr']))        \n",
    "\n",
    "\n",
    "acq = tfd_data.Acquisition(stack_scaled.astype(np.uint8),psf.astype(np.uint8))\n",
    "logging.info(acq.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the deconvolution process and note that deconvolution initialization is best kept separate from \n",
    "# execution since the \"initialize\" operation corresponds to creating a TensorFlow graph, which is a \n",
    "# relatively expensive operation and should not be repeated across multiple executions\n",
    "#\n",
    "# In case you experience CUDA memory errors, remove the observer and add pad_mode='none'\n",
    "\n",
    "channels = 0\n",
    "niter = 100\n",
    "logging.info(\"Starting GPU decon!\")\n",
    "algo = tfd_restoration.RichardsonLucyDeconvolver(n_dims=3,observer_fn=observer).initialize()\n",
    "res = algo.run(acq, niter=niter)\n",
    "logging.info(\"Finished successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(scores).T.plot(subplots=True, figsize=(18, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the iterations\n",
    "n = 32\n",
    "iters = np.linspace(0, niter-1, num=n).astype(int)\n",
    "fig, axs = plt.subplots(4, 8)\n",
    "axs = axs.ravel()\n",
    "fig.set_size_inches(24, 12)\n",
    "for i, j in enumerate(iters):\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title('iteration {}'.format(j))\n",
    "    axs[i].imshow(imgs[j].max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MIPs at high res\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs = axs.ravel()\n",
    "fig.set_size_inches(30, 15)\n",
    "center = tuple([slice(None), slice(10, -10), slice(10, -10)])\n",
    "titles = ['Original Image', 'Deconvolved Image']\n",
    "for i, d in enumerate([stack_scaled, res.data ]):#res.data\n",
    "    img = exposure.adjust_gamma(d[center].max(axis=0), gamma=.2)\n",
    "    axs[i].imshow(img, cmap='Spectral_r')\n",
    "    axs[i].set_title(titles[i])\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot xz-projections\n",
    "fig, axs = plt.subplots(2,1)\n",
    "axs = axs.ravel()\n",
    "fig.set_size_inches(30, 30)\n",
    "xz_projection_data = np.max(stack_scaled, axis=1)\n",
    "xz_projection_decon = np.max(res.data, axis=1)\n",
    "titles = ['Original Image', 'Deconvolved Image']\n",
    "for i, d in enumerate([xz_projection_data, xz_projection_decon]):#res.data\n",
    "    img = exposure.adjust_gamma(d,gamma=.2)\n",
    "    axs[i].imshow(img, cmap='Spectral_r')\n",
    "    axs[i].set_title(titles[i])\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot a selectable image from the stack\n",
    "def plot_image(i):\n",
    "    fig,(ax1,ax2) = plt.subplots(1,2, figsize=(20,10))\n",
    "    ax1.imshow(exposure.adjust_gamma(stack_scaled[i, slice(10, -10), slice(10, -10)],gamma=.2), cmap='Spectral_r')#)'gray'\n",
    "    ax2.imshow(exposure.adjust_gamma(res.data[i, slice(10, -10), slice(10, -10)],gamma=.2), cmap='Spectral_r')#'Spectral_r')'gray'\n",
    "    ax2.axis('off')\n",
    "    fig.show()\n",
    "\n",
    "# Create a slider widget\n",
    "slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=res.data.shape[0] - 1,\n",
    "    step=1,\n",
    "    description='Image Index:',\n",
    "    continuous_update=True\n",
    ")\n",
    "\n",
    "widgets.interactive(plot_image, i=slider) # Create an interactive widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images\n",
    "\n",
    "if LIFFILE:\n",
    "    from datetime import datetime    \n",
    "    io.imsave(output_folder + '_' + test_fov.FOV_name +'_deconv.tif',res.data.astype(np.float16))\n",
    "    if LOG_LEVEL == logging.DEBUG:\n",
    "        io.imsave(output_folder + '_' + test_fov.FOV_name +'_input.tif',stack_scaled)\n",
    "        io.imsave('./' + datetime.today().strftime(\"%Y-%m-%d_%H-%M-%S_\")  + test_fov.FOV_name + '_deconv.tif',res.data.astype(np.float16))\n",
    "        io.imsave('./' + datetime.today().strftime(\"%Y-%m-%d_%H-%M-%S_\")  + test_fov.FOV_name + '_input.tif',stack_scaled)\n",
    "        io.imsave('./' + datetime.today().strftime(\"%Y-%m-%d_%H-%M-%S_\")  + test_fov.FOV_name + '_MIP_deconv.tif',np.max(res.data.astype(np.float16),axis=0))\n",
    "        io.imsave('./' + datetime.today().strftime(\"%Y-%m-%d_%H-%M-%S_\")  + test_fov.FOV_name +'_MIP_input.tif',np.max(stack_scaled,axis=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
